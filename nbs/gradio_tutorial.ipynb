{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building `gradio` demos within `fastai`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load a `learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "Path.BASE_PATH = path\n",
    "fname = (path/\"images\").ls()[0]\n",
    "\n",
    "pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                 get_items=get_image_files, \n",
    "                 splitter=RandomSplitter(seed=42),\n",
    "                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "                 item_tfms=Resize(460),\n",
    "                 batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
    "dls = pets.dataloaders(path/\"images\")\n",
    "\n",
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn = learn.load('pets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the learner is ready we can immediately create a default demo. Without any parameters `demo` will read the type of `inputs` and `outputs` and create a barebones `Interface`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7863/\n",
      "This share link will expire in 72 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted\n",
      "Running on External URL: https://43744.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"https://43744.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f85d2fba220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also customize your demo by adding any of the parameters we support in the gradio `Interface` class (see [gradio.app/docs](gradio.app/docs)) directly into `demo`. For example below we'll add a title, description, and examples  to this interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7864/\n",
      "This share link will expire in 72 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted\n",
      "Running on External URL: https://13354.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"https://13354.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f85bdd277c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title=\"Pet classification\" \n",
    "description=\"Classify pets into 1 of 37 classes\"\n",
    "# downloading an image to use as an example\n",
    "urlretrieve(\"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/golden-retriever-royalty-free-image-506756303-1560962726.jpg\",\"dog.jpg\")\n",
    "examples = [[\"dog.jpg\"]]\n",
    "\n",
    "# simply pass in the new parameters you want to add to demo\n",
    "learn.demo(title=title, description=description, examples=examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also override the parameters that are inferred from `learner` (which are the `predict_fn`, `inputs`, and `outputs`) or set to `True` by default (`share` which creates an external url, `allow_screenshot` which adds a screenshot button, and `allow_flagging` which adds a flag button) \n",
    "\n",
    "We will change all of those below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7865/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7865/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f85a8d23820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining a new predict function that takes in an extra input (checkbox)\n",
    "def new_predict(image, remove_underscores):\n",
    "    preds = learn.predict(image.name)\n",
    "    output = {learn.dls.vocab[i]: float(preds[2][i]) for i in range(len(learn.dls.vocab))}\n",
    "    if remove_underscores: \n",
    "        output = {key.replace(\"_\", \" \"): value for key, value in zip(output.keys(), output.values())}\n",
    "    return output\n",
    "\n",
    "# defining a list of inputs to add the checkbox \n",
    "inputs = [gr.inputs.Image(type=\"file\", label=\"image of pet\"), gr.inputs.Checkbox(label=\"remove underscores?\")]\n",
    "examples = [[\"dog.jpg\", True]]\n",
    "\n",
    "\n",
    "# defining a new output and increasing the top classes to 5 \n",
    "outputs = gr.outputs.Label(num_top_classes=5, label=\"breed\")\n",
    "\n",
    "# setting share = False to only run this locally \n",
    "share = False \n",
    "\n",
    "# no flagging, and no screenshot button \n",
    "allow_flagging = False; allow_screenshot = False \n",
    "\n",
    "# putting everything into demo \n",
    "learn.demo(predict_fn=new_predict, inputs=inputs, outputs=outputs, \n",
    "           share=share, allow_flagging=allow_flagging, allow_screenshot=allow_screenshot, \n",
    "           title=title, description=description, examples=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
